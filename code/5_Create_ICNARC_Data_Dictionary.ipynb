{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8f255-5050-4314-805d-d1079a145d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Notes \n",
    "#Open a terminal and run: conda install -c conda-forge scipy\n",
    "#then conda install -c conda-forge tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5445ac0-c36e-4c4a-aa5c-c8597e42cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_num_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a string with descriptive \n",
    "    statistics for the column specified.\n",
    "\n",
    "    Calculates the mean, median, max, min and IQR for the specified column using \n",
    "    BigQuery SQL and returns a string with the results concatenated together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of a the numeric column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the mean, median, max, min and IQR for the specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT\n",
    "                AVG({col_name}) AS mean,\n",
    "                MAX({col_name}) AS max,\n",
    "                MIN({col_name}) AS min,\n",
    "                APPROX_QUANTILES({col_name}, 2)[OFFSET(1)] AS median,\n",
    "                APPROX_QUANTILES({col_name}, 4)[OFFSET(1)] AS q1,\n",
    "                APPROX_QUANTILES({col_name}, 4)[OFFSET(3)] AS q3\n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT CONCAT('Mean: ', CAST(mean AS STRING),  \n",
    "                      ', Median: ', CAST(median AS STRING), \n",
    "                      ', Max: ', CAST(max AS STRING), \n",
    "                      ', Min: ', CAST(min AS STRING),  \n",
    "                      ', IQR: ', CAST(q3 - q1 AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_date_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a string with the min and max \n",
    "    dates.\n",
    "\n",
    "    Calculates the min and max dates for the specified column using BigQuery SQL \n",
    "    and returns a string with the results concatenated together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of a date column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the min and max dates for the specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT \n",
    "                MAX({col_name}) AS max_date, \n",
    "                MIN({col_name}) AS min_date \n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT\n",
    "            CONCAT('From: ', CAST(min_date AS STRING), \n",
    "                   ' To: ', CAST(max_date AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_bool_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a the count of `True` and \n",
    "    `False` values.\n",
    "\n",
    "    Calculates the count of `True` and `False` values for the specified column \n",
    "    using BigQuery SQL and returns a string with the results concatenated \n",
    "    together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of the boolean column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the count of `True` and `False` values for the \n",
    "             specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT\n",
    "                COUNTIF({col_name} = TRUE) AS true_count,\n",
    "                COUNTIF({col_name} = FALSE) AS false_count\n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT\n",
    "            CONCAT('False: ', CAST(false_count AS STRING), \n",
    "                   ', True: ', CAST(true_count AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_string_description_column(col_name, table_name):\n",
    "    sql_query = f\"\"\"\n",
    "        WITH top_entries AS (\n",
    "            SELECT {col_name}, COUNT(*) AS count\n",
    "            FROM `{table_name}`\n",
    "            GROUP BY {col_name}\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 5 \n",
    "        ),\n",
    "        total_entries AS (\n",
    "            SELECT COUNT(DISTINCT {col_name}) AS total_count\n",
    "            FROM `{table_name}` \n",
    "        )\n",
    "        SELECT IF((SELECT total_count FROM total_entries) > 5, \n",
    "                   CONCAT('Top 5: ', STRING_AGG(CONCAT({col_name}, ': ', \n",
    "                          CAST(count AS STRING)), ', ')), \n",
    "                   STRING_AGG(CONCAT({col_name}, ': ', \n",
    "                              CAST(count AS STRING)), ', '))\n",
    "        FROM top_entries\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def create_data_dict(dataset_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a data dictionary table for a BigQuery dataset.\n",
    "    \n",
    "    Takes the ID of a BigQuery dataset and creates a data_dict table in the same \n",
    "    dataset. `data_dict` contains information about tables in the \n",
    "    dataset with names prefixed \" tbl_\" or \"cb_\":\n",
    "    table name, column name, data type, and a summary \n",
    "    description of each column. `description` column includes summary statistics \n",
    "    for numeric columns (mean, median, IQR, min,  max), the number of unique \n",
    "    values and top 5 values for string columns, the  date range for date \n",
    "    columns, and the count of True and False values for boolean columns. \n",
    "    \n",
    "    Args:\n",
    "        dataset_id (str): The ID of the BigQuery dataset.\n",
    "        \n",
    "    Output:\n",
    "        None - `data_dict` table is uploaded to biqquery dataset at \"dataset_id\"\n",
    "    \"\"\"\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    tables = list(client.list_tables(dataset_ref))\n",
    "    rows = []\n",
    "    table_count = 0\n",
    "    output_dict = {\n",
    "        \"table_name\": [],\n",
    "        \"column_name\": [],\n",
    "        \"data_type\": [],\n",
    "        \"description\": []\n",
    "    }\n",
    "    for table in tables:\n",
    "        if table.table_id.startswith(\"tbl_\") or table.table_id.startswith(\"cb_\"):\n",
    "            table_count += 1\n",
    "            print(f\"Processing table {table_count} of {len(tables)}: {table.table_id}\")\n",
    "            table_ref = dataset_ref.table(table.table_id)\n",
    "            table = client.get_table(table_ref)\n",
    "            for schema_field in tqdm(table.schema):\n",
    "                output_dict[\"table_name\"].append(table.table_id)\n",
    "                output_dict[\"column_name\"].append(schema_field.name)\n",
    "                output_dict[\"data_type\"].append(schema_field.field_type)\n",
    "                full_table_id = f\"{dataset_id}.{table.table_id}\"\n",
    "                if schema_field.field_type == \"STRING\":\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_string_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"INTEGER\", \"FLOAT\", \"NUMERIC\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_num_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"DATE\", \"TIMESTAMP\", \"DATETIME\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_date_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"BOOL\", \"BOOLEAN\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_bool_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "    output_df = pd.DataFrame(output_dict)\n",
    "    output_df.to_gbq(f\"{dataset_id}.data_dictionary\", progress_bar=False)\n",
    "    print(\"Finished creating data_dict table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71c9c81-a37a-4acb-aa55-59f595389957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 1 of 49: cb_CIN_2009_to_2019_Disability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 2 of 49: cb_MappingCodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 3 of 49: cb_QualCodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 4 of 49: tbl_Census\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:25<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 5 of 49: tbl_ChildrenInNeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:25<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 6 of 49: tbl_ChildrenInNeed_2009_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:32<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 7 of 49: tbl_ChildrenLookedAfter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 8 of 49: tbl_ChildrenLookedAfter_2006_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:16<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 9 of 49: tbl_EYFSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [01:47<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 10 of 49: tbl_Exclusions_All\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [01:51<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 11 of 49: tbl_ILR_Aims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [03:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 12 of 49: tbl_ILR_Learner_1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [02:31<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 13 of 49: tbl_KS1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [01:12<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 14 of 49: tbl_KS1_1998_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [01:15<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 15 of 49: tbl_KS2_1999_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 466/466 [05:53<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 16 of 49: tbl_KS2_exam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:42<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 17 of 49: tbl_KS2_exam_formatted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:34<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 18 of 49: tbl_KS2_formatted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 467/467 [05:40<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 19 of 49: tbl_KS2_pupil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 467/467 [04:38<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 20 of 49: tbl_KS3Exam_2007_to_2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 21 of 49: tbl_KS3TA_2009_to_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:38<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 22 of 49: tbl_KS3_exam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:20<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 23 of 49: tbl_KS3_pupil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [02:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 24 of 49: tbl_KS4_exam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:10<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 25 of 49: tbl_KS4_pupil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 661/661 [06:40<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 26 of 49: tbl_KS5_exam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:53<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 27 of 49: tbl_KS5_pupil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [06:44<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 28 of 49: tbl_NCCIS_2011_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:23<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 29 of 49: tbl_Phonics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 30 of 49: tbl_Phonics_2012_to_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 31 of 49: tbl_ProgressTestsYr7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:26<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 32 of 49: tbl_ProgressTests_Year_2001_to_2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:27<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 33 of 49: tbl_YPMAD_Indicators_1819_Chronological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [02:04<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 34 of 49: tbl_YPMAD_Indicators_1819_Snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [01:11<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 35 of 49: tbl_absence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [01:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 36 of 49: tbl_census\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 37 of 49: tbl_change_log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 38 of 49: tbl_post16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:29<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating data_dict table\n"
     ]
    }
   ],
   "source": [
    "create_data_dict(\"CB_FDM_DepartmentForEducation_V2\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
